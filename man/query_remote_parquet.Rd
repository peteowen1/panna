% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/data_loaders.R
\name{query_remote_parquet}
\alias{query_remote_parquet}
\title{Query Remote Parquet with SQL (Primary Method)}
\usage{
query_remote_parquet(
  table_name,
  sql_template,
  release = NULL,
  tag = "fbref-latest"
)
}
\arguments{
\item{table_name}{Character. Name of the parquet file (without .parquet).}

\item{sql_template}{Character. SQL query template with \code{\{table\}} placeholder.}

\item{release}{Optional. Release info from \code{get_latest_release()}.}

\item{tag}{Character. GitHub release tag to download from. Defaults to "fbref-latest".}
}
\value{
Data frame with query results.
}
\description{
Downloads a parquet file from GitHub releases to a temp file, then runs
a SQL query on it using DuckDB. This is much faster than downloading
entire ZIP files because:
\enumerate{
\item Download is done once with optimized HTTP
\item DuckDB queries local file (no network latency per query)
\item Only filtered/aggregated results come into R memory
}
}
\examples{
\dontrun{
# Load all summary data
sql <- "SELECT * FROM {table}"
result <- query_remote_parquet("summary", sql)

# Load filtered data (filtering happens in SQL, not R!)
sql <- "SELECT * FROM {table} WHERE league = 'ENG' AND season = '2023-2024'"
eng_2023 <- query_remote_parquet("summary", sql)
}
}
